I"ƒb<p>We are excited to release the real-time Root Cause Analysis engine for Elasticsearch in 
<a href="https://opendistro.github.io/for-elasticsearch/blog/odfe-updates/2020/07/Open-Distro-for-Elasticsearch-1.9.0-is-released/">Open Distro for Elasticsearch version 1.9.0</a>. 
The RCA engine enables operators to diagnose and identify bottlenecks in their Elasticsearch clusters. 
This is a value-add feature on top of the current array of low-level metrics they have access to with Performance Analyzer. 
Operators can leverage the RCA to tune the relevant Elasticsearch settings and adjust the workloads to ensure cluster 
stability and performance. In this blog, we dive into some aspects of the RCA engine and how it can be leveraged for 
Elasticsearch cluster diagnosis.</p>

<h2 id="introduction">Introduction</h2>

<p>Elasticsearch can be difficult to manage, especially at scale. We released <a href="https://github.com/opendistro-for-elasticsearch/performance-analyzer">Performance Analyzer</a>
to provide deep visibility into Elasticsearch shards, nodes, storage and network resources to quantify resource health 
and usage (starvation, overuse and contention). However, operators are required to have deep insights into 
Elasticsearch to debug and identify the root cause once things start to go sideways. The RCA engine is incredibly useful 
for reducing the operational burden of Elasticsearch clusters. Several mission-critical systems and applications rely 
on Elasticsearch and when the cluster experiences performance or stability issues, it is critical to get it back on 
track as quickly as possible. RCA engine helps operators transition immediately from being alerted about an issue to 
executing remediation actions. RCA uses the metrics emitted by the Performance Analyzer to infer and pinpoint 
performance and reliability problems in the database and the underlying infrastructure layers. 
RCAs are designed to diagnose the problems, with accuracy (precision and recall), and in the shortest time possible for 
that accuracy level.</p>

<p>Let‚Äôs examine a use case on how RCA engine can be utilized. Imagine you are managing a 3 node Elasticsearch cluster 
(nodes A, B, and C) containing indexes without any replicas. The cluster health appears GREEN, but every few minutes, 
the query rejection rate spikes up. While investigating this issue, you notice that all the data for the rejected 
queries resides on node B. Using Performance Analyzer metrics, you notice that the JVM memory pressure and CPU 
utilization metrics coming from Node B follows a sawtooth pattern.</p>

<p>These metrics line up with the query rejections you noticed, great! While you‚Äôve made progress on your investigation, 
you still don‚Äôt know the root cause of this behavior. Is it the CPU or the memory? How can you fix the issue? 
At this point, you might be tempted to simply restart the Elasticsearch node. When you restart your node, the spiky 
behavior stops! Everything seems to go back to normal until you get paged a few minutes later with the exact same issue. 
Time for more investigation now ‚Ä¶</p>

<p>This investigation process can be tiring and may breach your service SLAs. This is where the RCA engine comes in handy 
and helps alleviate the burden involved in debugging Elasticsearch issues. Let‚Äôs examine how we could investigate the 
exact same issue with the help of the RCA engine.</p>

<ol>
  <li>We notice something is wrong so we issue a general RCA query to our elected master node A
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> curl &lt;master node&gt;:9600/_opendistro/_performanceanalyzer/rca -XGET
</code></pre></div>    </div>
  </li>
  <li>Most of our resources look healthy, but the HighHeapUsageClusterRca is in an unhealthy state. So we drill down into that specific RCA using
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl &lt;master node&gt;:9600/_opendistro/_performanceanalyzer/rca?name=HighHeapUsageClusterRca -XGET
</code></pre></div>    </div>
  </li>
  <li>Look at the RCA response, see if anything stands out to you:</li>
  <li>
    <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">  </span><span class="p">{</span><span class="w">
    </span><span class="nl">"HighHeapUsageClusterRca"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"rca_name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HighHeapUsageClusterRca"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"state"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unhealthy"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"timestamp"</span><span class="p">:</span><span class="w"> </span><span class="mi">1587426650942</span><span class="p">,</span><span class="w">
            </span><span class="nl">"HotClusterSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="p">{</span><span class="w">
                    </span><span class="nl">"number_of_nodes"</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"number_of_unhealthy_nodes"</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"HotNodeSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                        </span><span class="p">{</span><span class="w">
                            </span><span class="nl">"host_address"</span><span class="p">:</span><span class="w"> </span><span class="s2">"192.168.0.X"</span><span class="p">,</span><span class="w">
                            </span><span class="nl">"node_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"JtlEoRowSI6iNpzpjlbp_Q"</span><span class="p">,</span><span class="w">
                            </span><span class="nl">"HotResourceSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                                </span><span class="p">{</span><span class="w">
                                    </span><span class="nl">"resource_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"young gen"</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"unit_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"promotion rate in mb/s"</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"threshold"</span><span class="p">:</span><span class="w"> </span><span class="mi">400</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"value"</span><span class="p">:</span><span class="w"> </span><span class="mi">500</span><span class="p">,</span><span class="w">
                                    </span><span class="err">...</span><span class="w">
                                </span><span class="p">}</span><span class="w">
                            </span><span class="p">]</span><span class="w">
                        </span><span class="p">}</span><span class="w">
                    </span><span class="p">]</span><span class="w"> 
                </span><span class="p">}</span><span class="w">
            </span><span class="p">]</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div>    </div>
  </li>
  <li>Notice that while your acceptable young garbage collection (GC) promotion rate is 400 MB/s, 
the actual rate on node B is 500 MB/s. You can conclude that this young generation promotion rate is the most likely 
candidate for your cluster‚Äôs spiky, degraded performance. When objects are quickly promoted from the young generation, 
they start to fill up the old generation (or tenured space) of the JVM heap. Once the tenured space becomes full, 
an expensive event called Major GC takes place. When this occurs, the JVM stops executing instructions until the 
garbage collection completes. This garbage collection operation can be CPU intensive as well. The solution to this 
problem can be a simple change to the young generation size by altering 
<code class="language-plaintext highlighter-rouge">-XX:NewSize, -XX:MaxNewSize and -XX:SurvivorRatio</code> parameters of the Elasticsearch process.</li>
</ol>

<p>RCA particularly shines at scale. Imagine the same problem discussed above in a larger, 100 node multi-tenant production 
cluster. Manual diagnosis of the issue is like finding a needle in a haystack, but isolating the problem using RCA 
follows the same basic steps: issue a query to the master, read the output, and take appropriate actions. RCA framework is 
powerful, lightweight and highly extensible that enables you to write your own RCAs for the
<a href="https://opendistro.github.io/for-elasticsearch-docs/docs/pa/reference/">resources</a> or combination of resources that are
important for your particular cluster. We plan to release a series of blogs with the RCAs that you can leverage and reduce 
the mean time to repair (MTTR) your cluster.</p>

<h2 id="rca-framework-system-design">RCA Framework System Design</h2>

<p>We define a root cause as a function of one or more symptoms and/or one or more RCAs and metric(s). 
A symptom is an operation applied to one or more metrics and/or other symptoms. Root causes may also be a function of 
other root causes. The following equations show an example of these relationships</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>// A resource state is a function of one or many metrics and theresholds. The
// function over the metrics and threshold is the evaluation function.
resource_state = f(metric1, threshold1)

// An rca is a function of one or many resource states and other metrics and some
// other RCAs. Not all of them are required.
rca = g(resource_state, metric2, threshold2, rca1)
</code></pre></div></div>
<p>The RCA framework is modeled as a distributed data-flow graph (see Fig 1) where data flows downstream from the leaf 
nodes to the root. Leaf nodes of the graph represent Performance Analyzer metrics on which intermediate computations 
are performed. The intermediate nodes can be RCAs or other derived symptoms which helps in computation of the final 
RCA(s). The framework operates on a single analysis graph which is composed of multiple connected-components.</p>

<p><img src="//assets/media/blog-images/2020-07-09-Introducing-Real-Time-Root-Cause-Analysis-Engine-in-Elasticsearch/rca-multilevel-graph.jpg" alt="RCA Multilevel Graph" class="img-fluid" /></p>
<ul>
  <li>Fig 1: A multi-level RCA graph composed of metrics and thresholds</li>
</ul>

<p>Execution of an RCA is the evaluation of the data-flow graph on the physical nodes of the cluster (Fig 2). 
We evaluate the RCA directed acyclic graph (DAG) in a particular order such that all the data for the RCA is available 
when it is being evaluated. Nodes in the cluster can also communicate among themselves to share the output of graph 
evaluations. For simplicity, we let only the currently active master node listen to the output emitted by other 
data nodes.</p>

<p><img src="//assets/media/blog-images/2020-07-09-Introducing-Real-Time-Root-Cause-Analysis-Engine-in-Elasticsearch/rca-execution-model.jpg" alt="RCA Execution Model" class="img-fluid" /></p>
<ul>
  <li>Fig 2: Execution model of RCA graph across Elasticsearch nodes</li>
</ul>

<h2 id="rca-to-diagnose-high-heap-usage">RCA to diagnose high heap usage</h2>

<p>Most Elasticsearch clusters perform reasonably well when they are configured with the right JVM heap pressure with 
right configuration settings. However, the heap pressure in Elasticsearch could shoot up for a variety of reasons 
such as organic growth in traffic, spike in customer requests, rogue queries etc.  We‚Äôve leveraged the RCA framework 
and created two JVM RCAs to help you identify and diagnose heap pressure issues. Out of the box, you‚Äôll get access to 
the <code class="language-plaintext highlighter-rouge">HighHeapUsageClusterRca</code>, which diagnose old and young generation issues in the JVM garbage collector. By querying 
the RCA API, you‚Äôll be able to quickly identify if your GC is unhealthy and which consumers (fielddata cache/request 
cache, Lucene segment memories, etc.) are consuming the most memory.</p>

<p><img src="//assets/media/blog-images/2020-07-09-Introducing-Real-Time-Root-Cause-Analysis-Engine-in-Elasticsearch/high-heap-usage-cluster-rca.png" alt="HighHeapUsageClusterRca" class="img-fluid" /></p>

<h2 id="api-usage">API Usage</h2>

<p>Use the API below on the <em>elected master node</em> to get a cluster level view of the JVM RCA output.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl --url "localhost:9600/_opendistro/_performanceanalyzer/rca?name=HighHeapUsageClusterRca" -XGET
</code></pre></div></div>

<p>Sample RCA response from above API</p>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
    </span><span class="nl">"HighHeapUsageClusterRca"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"rca_name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HighHeapUsageClusterRca"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"state"</span><span class="p">:</span><span class="w"> </span><span class="s2">"unhealthy"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"timestamp"</span><span class="p">:</span><span class="w"> </span><span class="mi">1587426650942</span><span class="p">,</span><span class="w">
            </span><span class="nl">"HotClusterSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                </span><span class="p">{</span><span class="w">
                    </span><span class="nl">"number_of_nodes"</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"number_of_unhealthy_nodes"</span><span class="p">:</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w">
                    </span><span class="nl">"HotNodeSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                        </span><span class="p">{</span><span class="w">
                            </span><span class="nl">"host_address"</span><span class="p">:</span><span class="w"> </span><span class="s2">"192.168.144.X"</span><span class="p">,</span><span class="w">
                            </span><span class="nl">"node_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"JtlEoRowSI6iNpzpjlbp_Q"</span><span class="p">,</span><span class="w">
                            </span><span class="nl">"HotResourceSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                                </span><span class="p">{</span><span class="w">
                                    </span><span class="nl">"resource_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"old gen"</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"threshold"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.65</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"value"</span><span class="p">:</span><span class="w"> </span><span class="mf">0.81827232588145373</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"avg"</span><span class="p">:</span><span class="w"> </span><span class="err">NaN</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"max"</span><span class="p">:</span><span class="w"> </span><span class="err">NaN</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"min"</span><span class="p">:</span><span class="w"> </span><span class="err">NaN</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"unit_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"heap usage in percentage"</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"time_period_seconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">600</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"TopConsumerSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                                        </span><span class="p">{</span><span class="w">
                                            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CACHE_FIELDDATA_SIZE"</span><span class="p">,</span><span class="w">
                                            </span><span class="nl">"value"</span><span class="p">:</span><span class="w"> </span><span class="mi">5907025640</span><span class="w">
                                        </span><span class="p">},</span><span class="w">
                                        </span><span class="p">{</span><span class="w">
                                            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CACHE_REQUEST_SIZE"</span><span class="p">,</span><span class="w">
                                            </span><span class="nl">"value"</span><span class="p">:</span><span class="w"> </span><span class="mi">28375</span><span class="w">
                                        </span><span class="p">},</span><span class="w">
                                        </span><span class="p">{</span><span class="w">
                                            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CACHE_QUERY_SIZE"</span><span class="p">,</span><span class="w">
                                            </span><span class="nl">"value"</span><span class="p">:</span><span class="w"> </span><span class="mi">12687</span><span class="w">
                                        </span><span class="p">}</span><span class="w">
                                    </span><span class="p">],</span><span class="w">
                                </span><span class="p">}</span><span class="w">
                            </span><span class="p">]</span><span class="w">
                        </span><span class="p">},</span><span class="w">
                        </span><span class="p">{</span><span class="w">
                            </span><span class="nl">"host_address"</span><span class="p">:</span><span class="w"> </span><span class="s2">"192.168.144.Y"</span><span class="p">,</span><span class="w">
                            </span><span class="nl">"node_id"</span><span class="p">:</span><span class="w"> </span><span class="s2">"v2gdRXDFQHioIULQ5vn_7A"</span><span class="p">,</span><span class="w">
                            </span><span class="nl">"HotResourceSummary"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
                                </span><span class="p">{</span><span class="w">
                                    </span><span class="nl">"resource_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"young gen"</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"threshold"</span><span class="p">:</span><span class="w"> </span><span class="mf">400.0</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"value"</span><span class="p">:</span><span class="w"> </span><span class="mf">512.8</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"avg"</span><span class="p">:</span><span class="w"> </span><span class="err">NaN</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"max"</span><span class="p">:</span><span class="w"> </span><span class="err">NaN</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"min"</span><span class="p">:</span><span class="w"> </span><span class="err">NaN</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"unit_type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"promotion rate in mb/s"</span><span class="p">,</span><span class="w">
                                    </span><span class="nl">"time_period_seconds"</span><span class="p">:</span><span class="w"> </span><span class="mi">600</span><span class="p">,</span><span class="w">
                                </span><span class="p">}</span><span class="w">
                            </span><span class="p">]</span><span class="w">
                        </span><span class="p">}</span><span class="w">
                    </span><span class="p">]</span><span class="w"> 
                </span><span class="p">}</span><span class="w">
            </span><span class="p">]</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div>

<p>The JVM RCA API response returns a list of nodes in the cluster that are marked unhealthy. Each unhealthy node is 
augmented with a nested list of unhealthy JVM resources. From the list resource summaries, we can quickly identify the 
root cause of the JVM issue. i.e. whether the heap contention is from the old generation or the young generation of the 
JVM heap and the resource metrics that breach the set thresholds.</p>

<p>In the sample response above, two out of three nodes in the cluster are under JVM pressure and one node has old 
generation contention while the other has young generation issue. Let‚Äôs assume that we set the GC parameter 
<code class="language-plaintext highlighter-rouge">XX:CMSInitiatingOccupancyFraction</code> to 75 when we start the ES process. This setting means that Major GC will kick in 
once heap usage is above 75%.  However, from the sample response, node with ip address ‚Äú192.168.144.X‚Äù which is
 experiencing old generation contention has 81% occupancy even after a Major GC. This points to the fact that a huge 
 chunk of old generation heap is occupied by long lived objects that can not be garbage collected. So our next question 
 is what are those long lived objects? Luckily the <strong>TopConsumer</strong> field in this json output provides us that 
 information and fielddata cache is the top consumer (5.9GB). So the easiest way to mitigate this issue is to clear the 
 fielddata cache and set limits for the fielddata cache to say, 40% of node heap space to improve the cluster stability.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The new RCA engine enables you to quickly diagnose performance bottlenecks in your Elasticsearch cluster in an 
automated fashion. It leverages deep metric insights provided by Performance Analyzer to isolate the root cause. 
We plan to add RCAs for other commonly encountered bottlenecks in Elasticsearch clusters and a decision maker framework 
that collates RCA outputs and provides unified recommendations in the future.</p>

<p>We encourage you to try out this solution on Open Distro for Elasticsearch and provide your valuable feedback to our 
engineering team at https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca. We also invite you to 
contribute to this feature. Check out the contribution guidelines <a href="https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/blob/master/CONTRIBUTING.md">here</a> 
to get more involved in the project.</p>
:ET